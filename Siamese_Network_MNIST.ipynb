{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Siamese_Network_MNIST.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8mq9gKRf7kF",
        "colab_type": "code",
        "outputId": "180e22c1-7a10-4917-d925-4173d32ebd93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCVa9MEMgKCP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e991faed-066c-4d1c-d5b6-10e4a184e3bc"
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "\n",
        "import random\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Input, Flatten, Dense, Dropout, Lambda, Conv2D, MaxPooling2D\n",
        "from keras.optimizers import RMSprop\n",
        "from keras import backend as K\n",
        "\n",
        "num_classes = 10\n",
        "epochs = 20\n",
        "\n",
        "\n",
        "def euclidean_distance(vects):\n",
        "    x, y = vects\n",
        "    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
        "    return K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
        "\n",
        "\n",
        "def eucl_dist_output_shape(shapes):\n",
        "    shape1, shape2 = shapes\n",
        "    return (shape1[0], 1)\n",
        "\n",
        "\n",
        "def contrastive_loss(y_true, y_pred):\n",
        "    '''Contrastive loss from Hadsell-et-al.'06\n",
        "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
        "    '''\n",
        "    margin = 1\n",
        "    sqaure_pred = K.square(y_pred)\n",
        "    margin_square = K.square(K.maximum(margin - y_pred, 0))\n",
        "    return K.mean((y_true) * sqaure_pred + (1 - y_true) * margin_square)\n",
        "\n",
        "\n",
        "def create_pairs(x, digit_indices):\n",
        "    '''Positive and negative pair creation.\n",
        "    Alternates between positive and negative pairs.\n",
        "    '''\n",
        "    pairs = []\n",
        "    labels = []\n",
        "    n = min([len(digit_indices[d]) for d in range(num_classes)]) - 1\n",
        "    for d in range(num_classes):\n",
        "        for i in range(n):\n",
        "            z1, z2 = digit_indices[d][i], digit_indices[d][i + 1]\n",
        "            pairs += [[x[z1], x[z2]]]\n",
        "            inc = random.randrange(1, num_classes)\n",
        "            dn = (d + inc) % num_classes\n",
        "            z1, z2 = digit_indices[d][i], digit_indices[dn][i]\n",
        "            pairs += [[x[z1], x[z2]]]\n",
        "            labels += [0, 1]\n",
        "    return np.array(pairs), np.array(labels)\n",
        "\n",
        "\n",
        "def create_base_network(input_shape):\n",
        "    '''Base network to be shared (eq. to feature extraction).\n",
        "    '''\n",
        "    input = Input(shape=(28, 28, 1))\n",
        "#     model = Sequential()\n",
        "    x = Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape)(input)\n",
        "    x = Conv2D(64, (3, 3), activation='relu')(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = Dropout(0.25)(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "#     model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "#               optimizer=keras.optimizers.Adadelta(),\n",
        "#               metrics=['accuracy'])\n",
        "#     model.summary()\n",
        "#       x = Flatten()(input)\n",
        "#     x = Dense(128, activation='relu')(x)\n",
        "#     x = Dropout(0.1)(x)\n",
        "#     x = Dense(128, activation='relu')(x)\n",
        "#     x = Dropout(0.1)(x)\n",
        "#     x = Dense(128, activation='relu')(x)\n",
        "    return Model(input, x)\n",
        "\n",
        "\n",
        "def compute_accuracy(y_true, y_pred):\n",
        "    '''Compute classification accuracy with a fixed threshold on distances.\n",
        "    '''\n",
        "    pred = y_pred.ravel() < 50\n",
        "    return np.mean(pred == y_true)\n",
        "\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "    '''Compute classification accuracy with a fixed threshold on distances.\n",
        "    '''\n",
        "    return K.mean(K.equal(y_true, K.cast(y_pred < 0.5, y_true.dtype)))\n",
        "\n",
        "\n",
        "# the data, split between train and test sets\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1Zzjp9J1MKM",
        "colab_type": "code",
        "outputId": "412ab6a4-3fe9-4d84-a907-8907d09b9447",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "input_shape = x_train.shape[1:]\n",
        "\n",
        "#Swagam addition\n",
        "x_train = x_train.reshape(x_train.shape[0],x_train.shape[1],x_train.shape[2],1)\n",
        "x_test = x_test.reshape(x_test.shape[0],x_test.shape[1],x_test.shape[2],1)\n",
        "input_shape = x_train.shape[1:]\n",
        "\n",
        "\n",
        "# create training+test positive and negative pairs\n",
        "digit_indices = [np.where(y_train == i)[0] for i in range(num_classes)]\n",
        "tr_pairs, tr_y = create_pairs(x_train, digit_indices)\n",
        "\n",
        "digit_indices = [np.where(y_test == i)[0] for i in range(num_classes)]\n",
        "te_pairs, te_y = create_pairs(x_test, digit_indices)\n",
        "\n",
        "print(input_shape)\n",
        "# network definition\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-i08C6yF2hsg",
        "colab_type": "code",
        "outputId": "f25471fe-6e48-4d71-ba03-979754e2abc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "input2 = Input(shape=input_shape)\n",
        "print(input2)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=(28, 28, 1)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# model.summary()\n",
        "# model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "#               optimizer=keras.optimizers.Adadelta(),\n",
        "#               metrics=['accuracy'])\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"input_1:0\", shape=(?, 28, 28, 1), dtype=float32)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jh0Oqs9eMZDp",
        "colab_type": "code",
        "outputId": "eebd4a6a-6ba1-4930-ae9e-3fd5aba6ea4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 836
        }
      },
      "source": [
        "base_network = create_base_network(input_shape)\n",
        "\n",
        "input_a = Input(shape=input_shape)\n",
        "input_b = Input(shape=input_shape)\n",
        "\n",
        "# because we re-use the same instance `base_network`,\n",
        "# the weights of the network\n",
        "# will be shared across the two branches\n",
        "processed_a = base_network(input_a)\n",
        "processed_b = base_network(input_b)\n",
        "\n",
        "distance = Lambda(euclidean_distance,\n",
        "                  output_shape=eucl_dist_output_shape)([processed_a, processed_b])\n",
        "\n",
        "model = Model([input_a, input_b], distance)\n",
        "print(tr_pairs[:, 0].shape)\n",
        "# train\n",
        "rms = RMSprop()\n",
        "model.compile(loss=contrastive_loss, optimizer=rms, metrics=[accuracy])\n",
        "model.fit([tr_pairs[:, 0], tr_pairs[:, 1]], tr_y,\n",
        "          batch_size=128,\n",
        "          epochs=epochs,\n",
        "          validation_data=([te_pairs[:, 0], te_pairs[:, 1]], te_y))\n",
        "\n",
        "# compute final accuracy on training and test sets\n",
        "y_pred = model.predict([tr_pairs[:, 0], tr_pairs[:, 1]])\n",
        "tr_acc = compute_accuracy(tr_y, y_pred)\n",
        "y_pred = model.predict([te_pairs[:, 0], te_pairs[:, 1]])\n",
        "te_acc = compute_accuracy(te_y, y_pred)\n",
        "\n",
        "print('* Accuracy on training set: %0.2f%%' % (100 * tr_acc))\n",
        "print('* Accuracy on test set: %0.2f%%' % (100 * te_acc))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(108400, 28, 28, 1)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 108400 samples, validate on 17820 samples\n",
            "Epoch 1/20\n",
            "108400/108400 [==============================] - 16s 144us/step - loss: 0.2743 - accuracy: 0.4974 - val_loss: 0.4871 - val_accuracy: 0.5000\n",
            "Epoch 2/20\n",
            "108400/108400 [==============================] - 13s 118us/step - loss: 0.2687 - accuracy: 0.4992 - val_loss: 0.4876 - val_accuracy: 0.5000\n",
            "Epoch 3/20\n",
            "108400/108400 [==============================] - 13s 116us/step - loss: 0.2666 - accuracy: 0.5007 - val_loss: 0.4908 - val_accuracy: 0.5000\n",
            "Epoch 4/20\n",
            "108400/108400 [==============================] - 13s 116us/step - loss: 0.2653 - accuracy: 0.4988 - val_loss: 0.4948 - val_accuracy: 0.5000\n",
            "Epoch 5/20\n",
            "108400/108400 [==============================] - 13s 115us/step - loss: 0.2642 - accuracy: 0.4989 - val_loss: 0.4955 - val_accuracy: 0.5000\n",
            "Epoch 6/20\n",
            "108400/108400 [==============================] - 13s 115us/step - loss: 0.2630 - accuracy: 0.5020 - val_loss: 0.4962 - val_accuracy: 0.5000\n",
            "Epoch 7/20\n",
            "108400/108400 [==============================] - 13s 119us/step - loss: 0.2626 - accuracy: 0.5013 - val_loss: 0.4970 - val_accuracy: 0.5000\n",
            "Epoch 8/20\n",
            "108400/108400 [==============================] - 13s 116us/step - loss: 0.2621 - accuracy: 0.5003 - val_loss: 0.4966 - val_accuracy: 0.5000\n",
            "Epoch 9/20\n",
            "108400/108400 [==============================] - 13s 116us/step - loss: 0.2625 - accuracy: 0.5004 - val_loss: 0.4971 - val_accuracy: 0.5000\n",
            "Epoch 10/20\n",
            "108400/108400 [==============================] - 13s 116us/step - loss: 0.2628 - accuracy: 0.4977 - val_loss: 0.4978 - val_accuracy: 0.5000\n",
            "Epoch 11/20\n",
            "108400/108400 [==============================] - 13s 116us/step - loss: 0.2622 - accuracy: 0.5000 - val_loss: 0.4978 - val_accuracy: 0.5000\n",
            "Epoch 12/20\n",
            "108400/108400 [==============================] - 12s 115us/step - loss: 0.2619 - accuracy: 0.5030 - val_loss: 0.4977 - val_accuracy: 0.5000\n",
            "Epoch 13/20\n",
            "108400/108400 [==============================] - 13s 118us/step - loss: 0.2624 - accuracy: 0.4985 - val_loss: 0.4983 - val_accuracy: 0.5000\n",
            "Epoch 14/20\n",
            "108400/108400 [==============================] - 13s 120us/step - loss: 0.2618 - accuracy: 0.5012 - val_loss: 0.4997 - val_accuracy: 0.5000\n",
            "Epoch 15/20\n",
            "108400/108400 [==============================] - 13s 116us/step - loss: 0.2619 - accuracy: 0.4997 - val_loss: 0.4997 - val_accuracy: 0.5000\n",
            "Epoch 16/20\n",
            "108400/108400 [==============================] - 12s 115us/step - loss: 0.2619 - accuracy: 0.5007 - val_loss: 0.4989 - val_accuracy: 0.5000\n",
            "Epoch 17/20\n",
            "108400/108400 [==============================] - 13s 115us/step - loss: 0.2625 - accuracy: 0.4964 - val_loss: 0.4985 - val_accuracy: 0.5000\n",
            "Epoch 18/20\n",
            "108400/108400 [==============================] - 13s 116us/step - loss: 0.2624 - accuracy: 0.4977 - val_loss: 0.4985 - val_accuracy: 0.5000\n",
            "Epoch 19/20\n",
            "108400/108400 [==============================] - 13s 116us/step - loss: 0.2621 - accuracy: 0.5002 - val_loss: 0.4980 - val_accuracy: 0.5000\n",
            "Epoch 20/20\n",
            "108400/108400 [==============================] - 13s 119us/step - loss: 0.2619 - accuracy: 0.4991 - val_loss: 0.4986 - val_accuracy: 0.5000\n",
            "* Accuracy on training set: 50.00%\n",
            "* Accuracy on test set: 50.00%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBg_14x7Vsz7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoSyyxJPHiBu",
        "colab_type": "code",
        "outputId": "91f1b096-df94-46dc-c0b7-50fce2af5dd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "a = x_test[24]\n",
        "# print(a)\n",
        "print(a.shape)\n",
        "b = np.expand_dims(a, axis = 0)\n",
        "print(b.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(28, 28, 1)\n",
            "(1, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2G16xs4dIkS_",
        "colab_type": "code",
        "outputId": "7ceb3b34-d2f1-4b87-d266-1d3ffad60fc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(b)\n",
        "print(\"Original Image\\n\")\n",
        "plt.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-778de9e1ac67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Original Image\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, data, **kwargs)\u001b[0m\n\u001b[1;32m   2697\u001b[0m         \u001b[0mfilternorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimlim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2698\u001b[0m         resample=resample, url=url, **({\"data\": data} if data is not\n\u001b[0;32m-> 2699\u001b[0;31m         None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2700\u001b[0m     \u001b[0msci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2701\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1808\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1810\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1812\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5492\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5494\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5495\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    636\u001b[0m         if not (self._A.ndim == 2\n\u001b[1;32m    637\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[0;32m--> 638\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid dimensions for image data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Invalid dimensions for image data"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQYAAAD8CAYAAACVSwr3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNYZBUmMYJDWGQVJjGCQ1/wMKpFHVdp3xCwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6lrDQOLKCk-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make those columns into a array of 8-bits pixels\n",
        "# This array will be of 1D with length 784\n",
        "        # The pixel intensity values are integers from 0 to 255\n",
        "pixels = x_test[26]\n",
        "#pixels = np.array(pixels, dtype='uint8')\n",
        "pixels *= 255.\n",
        "\n",
        "        # Reshape the array into 28 x 28 array (2-dimensional array)\n",
        "pixels = pixels.reshape((28, 28))\n",
        "\n",
        "        # Plot\n",
        "plt.title('Label is {label}'.format(label=y_test[26]))\n",
        "plt.imshow(pixels, cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3yW6r7jMD8N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "im_1 = np.expand_dims(x_test[26], axis = 0)\n",
        "im_2 = np.expand_dims(x_test[98], axis = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xo-GFB10Kk1p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output = model.predict([im_1, im_2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0OeELgvLdlI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsUBX3BmMaZ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(y_test[26], y_test[98])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_owLFbfMgy9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install foolbox"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pws9oZgDSJJf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install keras scikit-learn imbalanced-learn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95zB6NKASNs_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from tensorflow.python.client import device_lib\n",
        "# device_lib.list_local_devices()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9n9umgdJUkKj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import numpy as np\n",
        "# import keras\n",
        "# from sklearn.datasets import fetch_lfw_people\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.metrics import confusion_matrix\n",
        "# %matplotlib inline\n",
        "# import matplotlib.pyplot as plt\n",
        "# from imblearn.over_sampling import RandomOverSampler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOh_1uFQUsaT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# lfw_people = fetch_lfw_people(min_faces_per_person=35, color=False, resize=1.0,\n",
        "#                               slice_=(slice(48, 202), slice(48, 202)))\n",
        "\n",
        "# X_lfw = lfw_people.images\n",
        "# Y_lfw = lfw_people.target\n",
        "# target_names = lfw_people.target_names\n",
        "# n_classes = target_names.shape[0]\n",
        "\n",
        "# print('number of examples: {}'.format(Y_lfw.shape[0]))\n",
        "# print('dimensionality of images: {}'.format(X_lfw.shape[1:]))\n",
        "# print('number of unique classes (people): {}'.format(n_classes))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tfbze3z2VF6T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# _ = plt.hist(y, bins=n_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkuncPRmVLeT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(lfw_people.images[0])\n",
        "# plt.imshow(lfw_people.images[0].astype(np.uint8))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFli21fqVPeE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# i = np.random.randint(len(lfw_people.images))\n",
        "# plt.imshow(lfw_people.images[i].astype(np.uint8))\n",
        "# plt.grid(False)\n",
        "# print(target_names[Y_lfw[i]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ucDVZMJVVzP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(lfw_people.images.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnGtw7W_7Gp1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def create_pairs_lfw(x, digit_indices):\n",
        "#     '''Positive and negative pair creation.\n",
        "#     Alternates between positive and negative pairs.\n",
        "#     '''\n",
        "#     pairs = []\n",
        "#     labels = []\n",
        "#     n = min([len(digit_indices[d]) for d in range(n_classes)]) - 1\n",
        "#     for d in range(n_classes):\n",
        "#         for i in range(n):\n",
        "#             z1, z2 = digit_indices[d][i], digit_indices[d][i + 1]\n",
        "#             pairs += [[x[z1], x[z2]]]\n",
        "#             inc = random.randrange(1, n_classes)\n",
        "#             dn = (d + inc) % n_classes\n",
        "#             z1, z2 = digit_indices[d][i], digit_indices[dn][i]\n",
        "#             pairs += [[x[z1], x[z2]]]\n",
        "#             labels += [0, 1]\n",
        "#     return np.array(pairs), np.array(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JuacHq4VZhg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# datagen = ImageDataGenerator(\n",
        "#     rotation_range=10,\n",
        "#     width_shift_range=0.1,\n",
        "#     height_shift_range=0.1,\n",
        "#     shear_range=0.05,\n",
        "#     zoom_range=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1FTFpGbVffq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from keras import Model\n",
        "\n",
        "# batch_size = 256\n",
        "# test_split = 0.2\n",
        "# base_lr = 0.01\n",
        "# epochs = 100\n",
        "\n",
        "# # train/test split\n",
        "# X_train_lfw, X_test_lfw, Y_train_lfw, Y_test_lfw = train_test_split(X_lfw, Y_lfw, test_size=test_split, \n",
        "#                                                     stratify=Y_lfw, random_state=42)\n",
        "\n",
        "# # oversampling each class to contain at least 256 examples\n",
        "# sampling_targets = np.maximum([256] * n_classes, np.bincount(Y_train_lfw))\n",
        "# ratio_dict = dict(zip(range(n_classes), sampling_targets))\n",
        "# ros = RandomOverSampler(ratio=ratio_dict, random_state=42)\n",
        "\n",
        "# X_train_shape = X_train_lfw.shape\n",
        "# X_train_lfw = np.reshape(X_train_lfw, (X_train_shape[0], -1))\n",
        "# X_train_lfw, Y_train_lfw = ros.fit_sample(X_train_lfw, Y_train_lfw)\n",
        "# X_train_lfw = np.reshape(X_train_lfw, (len(X_train_lfw),) + X_train_shape[1:])\n",
        "\n",
        "# # one-hot encoding of labels\n",
        "# # Y_train_lfw = keras.utils.to_categorical(Y_train_lfw, n_classes)\n",
        "# # Y_test_lfw = keras.utils.to_categorical(Y_test_lfw, n_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72I6KZTDWbVn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# X_train_lfw = X_train_lfw.reshape(X_train_lfw.shape[0], X_train_lfw.shape[1], X_train_lfw.shape[2],1)\n",
        "# X_test_lfw = X_test_lfw.reshape(X_test_lfw.shape[0], X_test_lfw.shape[1], X_test_lfw.shape[2],1)\n",
        "# input_shape = X_train_lfw.shape[1:]\n",
        "\n",
        "# print(Y_train_lfw.shape)\n",
        "# # create training+test positive and negative pairs\n",
        "# digit_indices = [np.where(Y_train_lfw == i)[0] for i in range(n_classes)]\n",
        "# tr_pairs_lfw, tr_y_lfw = create_pairs_lfw(X_train_lfw, digit_indices)\n",
        "# print(tr_pairs_lfw[:, 0].shape)\n",
        "# digit_indices = [np.where(Y_test_lfw == i)[0] for i in range(n_classes)]\n",
        "# te_pairs_lfw, te_y_lfw = create_pairs_lfw(X_test_lfw, digit_indices)\n",
        "\n",
        "# print(input_shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0fo_ofleHFx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def create_base_network_lfw(input_shape):\n",
        "#     '''Base network to be shared (eq. to feature extraction).\n",
        "#     '''\n",
        "#     input1 = Input(shape=(154, 154, 1))\n",
        "# #     model = Sequential()\n",
        "#     x = Conv2D(32, kernel_size=(3, 3),\n",
        "#                  activation='relu',\n",
        "#                  input_shape=(154, 154))(input1)\n",
        "#     x = Conv2D(64, (3, 3), activation='relu')(x)\n",
        "#     x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "#     x = Dropout(0.25)(x)\n",
        "#     x = Flatten()(x)\n",
        "#     x = Dense(128, activation='relu')(x)\n",
        "#     x = Dropout(0.25)(x)\n",
        "#     x = Dense(n_classes, activation='softmax')(x)\n",
        "\n",
        "# #     model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "# #               optimizer=keras.optimizers.Adadelta(),\n",
        "# #               metrics=['accuracy'])\n",
        "# #     model.summary()\n",
        "# #       x = Flatten()(input)\n",
        "# #     x = Dense(128, activation='relu')(x)\n",
        "# #     x = Dropout(0.1)(x)\n",
        "# #     x = Dense(128, activation='relu')(x)\n",
        "# #     x = Dropout(0.1)(x)\n",
        "# #     x = Dense(128, activation='relu')(x)\n",
        "#     return Model(input1, x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCqt-zHdVuyt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# base_network_lfw = create_base_network_lfw((154, 154))\n",
        "\n",
        "# input_a_lfw = Input(shape=(154, 154, 1))\n",
        "# input_b_lfw = Input(shape=(154, 154, 1))\n",
        "\n",
        "# # because we re-use the same instance `base_network`,\n",
        "# # the weights of the network\n",
        "# # will be shared across the two branches\n",
        "# processed_a_lfw = base_network_lfw(input_a_lfw)\n",
        "# processed_b_lfw = base_network_lfw(input_b_lfw)\n",
        "\n",
        "# distance = Lambda(euclidean_distance,\n",
        "#                   output_shape=eucl_dist_output_shape)([processed_a_lfw, processed_b_lfw])\n",
        "\n",
        "# model = Model([input_a_lfw, input_b_lfw], distance)\n",
        "\n",
        "# print(tr_pairs_lfw.shape)\n",
        "# # train\n",
        "# rms = RMSprop()\n",
        "# model.compile(loss=contrastive_loss, optimizer=rms, metrics=[accuracy])\n",
        "# model.fit([tr_pairs_lfw[:, 0], tr_pairs_lfw[:, 1]], tr_y_lfw,\n",
        "#           batch_size=128,\n",
        "#           epochs=20,\n",
        "#           validation_data=([te_pairs_lfw[:, 0], te_pairs_lfw[:, 1]], te_y_lfw))\n",
        "\n",
        "# # compute final accuracy on training and test sets\n",
        "# y_pred_train_lfw = model.predict([tr_pairs_lfw[:, 0], tr_pairs_lfw[:, 1]])\n",
        "# tr_acc_lfw = compute_accuracy(tr_y_lfw, y_pred_train_lfw)\n",
        "# y_pred_test_lfw = model.predict([te_pairs_lfw[:, 0], te_pairs_lfw[:, 1]])\n",
        "# te_acc_lfw = compute_accuracy(te_y_lfw, y_pred_test_lfw)\n",
        "\n",
        "# print('* Accuracy on training set: %0.2f%%' % (100 * tr_acc_lfw))\n",
        "# print('* Accuracy on test set: %0.2f%%' % (100 * te_acc_lfw))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOX6bs2zLqAj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "\n",
        "import random\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Flatten, Dense, Dropout, Lambda\n",
        "from keras.optimizers import RMSprop\n",
        "from keras import backend as K\n",
        "\n",
        "num_classes = 10\n",
        "epochs = 20\n",
        "\n",
        "\n",
        "def euclidean_distance(vects):\n",
        "    x, y = vects\n",
        "    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
        "    return K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
        "\n",
        "\n",
        "def eucl_dist_output_shape(shapes):\n",
        "    shape1, shape2 = shapes\n",
        "    return (shape1[0], 1)\n",
        "\n",
        "\n",
        "def contrastive_loss(y_true, y_pred):\n",
        "    '''Contrastive loss from Hadsell-et-al.'06\n",
        "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
        "    '''\n",
        "    margin = 1\n",
        "    sqaure_pred = K.square(y_pred)\n",
        "    margin_square = K.square(K.maximum(margin - y_pred, 0))\n",
        "    return K.mean(y_true * sqaure_pred + (1 - y_true) * margin_square)\n",
        "\n",
        "\n",
        "def create_pairs(x, digit_indices):\n",
        "    '''Positive and negative pair creation.\n",
        "    Alternates between positive and negative pairs.\n",
        "    '''\n",
        "    pairs = []\n",
        "    labels = []\n",
        "    n = min([len(digit_indices[d]) for d in range(num_classes)]) - 1\n",
        "    for d in range(num_classes):\n",
        "        for i in range(n):\n",
        "            z1, z2 = digit_indices[d][i], digit_indices[d][i + 1]\n",
        "            pairs += [[x[z1], x[z2]]]\n",
        "            inc = random.randrange(1, num_classes)\n",
        "            dn = (d + inc) % num_classes\n",
        "            z1, z2 = digit_indices[d][i], digit_indices[dn][i]\n",
        "            pairs += [[x[z1], x[z2]]]\n",
        "            labels += [1, 0]\n",
        "    return np.array(pairs), np.array(labels)\n",
        "\n",
        "\n",
        "def create_base_network(input_shape):\n",
        "    '''Base network to be shared (eq. to feature extraction).\n",
        "    '''\n",
        "    input = Input(shape=input_shape)\n",
        "    x = Flatten()(input)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = Dropout(0.1)(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = Dropout(0.1)(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    return Model(input, x)\n",
        "\n",
        "\n",
        "def compute_accuracy(y_true, y_pred):\n",
        "    '''Compute classification accuracy with a fixed threshold on distances.\n",
        "    '''\n",
        "    pred = y_pred.ravel() < 0.5\n",
        "    return np.mean(pred == y_true)\n",
        "\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "    '''Compute classification accuracy with a fixed threshold on distances.\n",
        "    '''\n",
        "    return K.mean(K.equal(y_true, K.cast(y_pred < 0.5, y_true.dtype)))\n",
        "\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "input_shape = x_train.shape[1:]\n",
        "\n",
        "# create training+test positive and negative pairs\n",
        "digit_indices = [np.where(y_train == i)[0] for i in range(num_classes)]\n",
        "tr_pairs, tr_y = create_pairs(x_train, digit_indices)\n",
        "\n",
        "digit_indices = [np.where(y_test == i)[0] for i in range(num_classes)]\n",
        "te_pairs, te_y = create_pairs(x_test, digit_indices)\n",
        "\n",
        "# network definition\n",
        "base_network = create_base_network(input_shape)\n",
        "\n",
        "input_a = Input(shape=input_shape)\n",
        "input_b = Input(shape=input_shape)\n",
        "\n",
        "# because we re-use the same instance `base_network`,\n",
        "# the weights of the network\n",
        "# will be shared across the two branches\n",
        "processed_a = base_network(input_a)\n",
        "processed_b = base_network(input_b)\n",
        "\n",
        "distance = Lambda(euclidean_distance,\n",
        "                  output_shape=eucl_dist_output_shape)([processed_a, processed_b])\n",
        "\n",
        "model = Model([input_a, input_b], distance)\n",
        "\n",
        "# train\n",
        "rms = RMSprop()\n",
        "model.compile(loss=contrastive_loss, optimizer=rms, metrics=[accuracy])\n",
        "model.fit([tr_pairs[:, 0], tr_pairs[:, 1]], tr_y,\n",
        "          batch_size=128,\n",
        "          epochs=epochs,\n",
        "          validation_data=([te_pairs[:, 0], te_pairs[:, 1]], te_y))\n",
        "\n",
        "# compute final accuracy on training and test sets\n",
        "y_pred = model.predict([tr_pairs[:, 0], tr_pairs[:, 1]])\n",
        "tr_acc = compute_accuracy(tr_y, y_pred)\n",
        "y_pred = model.predict([te_pairs[:, 0], te_pairs[:, 1]])\n",
        "te_acc = compute_accuracy(te_y, y_pred)\n",
        "\n",
        "print('* Accuracy on training set: %0.2f%%' % (100 * tr_acc))\n",
        "print('* Accuracy on test set: %0.2f%%' % (100 * te_acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQDIn4PBM_AS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pixels = x_test[20]\n",
        "#pixels = np.array(pixels, dtype='uint8')\n",
        "pixels *= 255.\n",
        "\n",
        "        # Reshape the array into 28 x 28 array (2-dimensional array)\n",
        "pixels = pixels.reshape((28, 28))\n",
        "\n",
        "        # Plot\n",
        "plt.title('Label is {label}'.format(label=y_test[20]))\n",
        "plt.imshow(pixels, cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZWwlGwlNhSl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "img = image.load_img(\"3_og.png\", color_mode = \"grayscale\", target_size=((28, 28)))\n",
        "og_image = image.img_to_array(img)\n",
        "\n",
        "img = image.load_img(\"3_og_1.png\", color_mode = \"grayscale\", target_size=((28, 28)))\n",
        "original_image = image.img_to_array(img)\n",
        "\n",
        "img = image.load_img(\"3_hack.png\", color_mode = \"grayscale\", target_size=((28, 28)))\n",
        "hack_image = image.img_to_array(img)\n",
        "\n",
        "im_1 = np.expand_dims(x_test[20], axis = 0)\n",
        "print(im_1.shape)\n",
        "im_2 = np.expand_dims(original_image, axis = 0)\n",
        "print(original_image.shape)\n",
        "\n",
        "og = original_image.reshape((1,28,28))\n",
        "fake = hack_image.reshape((1,28,28))\n",
        "og1 = og_image.reshape((1,28,28))\n",
        "# print(hack.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgERqOQgNtDS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output = model.predict([fake, fake])\n",
        "f = compute_accuracy(y_test[20], output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATk_lIQQRtGh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(output)\n",
        "print(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jc9lC0YS-Vq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(tr_y[0])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}